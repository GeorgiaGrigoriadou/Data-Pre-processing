{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5e4d7b62-47ef-4969-a624-06fa8b087542",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import wordnet\n",
    "# import emoji\n",
    "# from emoticon_fix import emoticon_fix\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "# nltk.download('stopwords')\n",
    "#nltk.download('wordnet')\n",
    "# nltk.download('omw-1.4')\n",
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab0ed8f-a44c-4c61-afe5-638033b7016b",
   "metadata": {},
   "source": [
    "# Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "14782405-7890-4242-9563-059504dc0bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Καθαρισμός κειμένου\n",
    "def clean_text(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    #  #Replace Emoticon/Emoji with Text\n",
    "    # text = emoji.demojize(text, language = lang )\n",
    "    # text = emoticon_fix.emoticon_fix(text)\n",
    "    # # remove mentions\n",
    "    text = re.sub(\"@[A-Za-z0-9]+\",\"\", text)\n",
    "    # # remove hashtags\n",
    "    text = re.sub(\"#[A-Za-z0-9_]+\",\"\", text)\n",
    "    # # remove links\n",
    "    text = re.sub('https:\\/\\/\\S+', '', text) \n",
    "    # # remove next line     \n",
    "    # text = re.sub(r'[^ \\w\\.]', '', text) \n",
    "    # # remove words containing numbers\n",
    "    # text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    text = text.lower()\n",
    "    #Remove digits:\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    #Remove punctuation and special characters:\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    #Normalize whitespace:\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "\n",
    "########################################################################\n",
    "# text ='''https://chatgpt.com/c/6fc8ae8d-1271-4868-83a4-4c155bbf1542\n",
    "\n",
    "# t5y6y6tfghfj'''\n",
    "# print(clean_text(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1270857a-71bc-47b4-8f04-82716d2b375a",
   "metadata": {},
   "source": [
    "# Remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6a626462-5fc9-41e3-9716-bff51316926c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Αφαίρεση stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    words = text.split()\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "#df['cleaned_comments'] = df['cleaned_comments'].apply(remove_stopwords)\n",
    "# text=\"this is a text full of content and we need to clean it up\"\n",
    "# print(remove_stopwords(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8631bfa6-e23d-4933-a2d9-b512df532dab",
   "metadata": {},
   "source": [
    "# Stemming "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d46c4836-741b-46cf-bd66-ca7c22ea6d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stemming\n",
    "# Initialize the stemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Function to perform stemming\n",
    "def stem_sentence(sentence):\n",
    "    words = nltk.word_tokenize(sentence)\n",
    "    stemmed_words = [stemmer.stem(word) for word in words]\n",
    "    return ' '.join(stemmed_words)\n",
    "\n",
    "# Example usage\n",
    "# sentence = \"The striped bats are hanging on their feet for best\"\n",
    "# stemmed_sentence = stem_sentence(sentence)\n",
    "# print(stemmed_sentence)\n",
    "#the stripe bat are hang on their feet for best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5feda531-926e-4ad7-833d-309a15a2e8d2",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4024b1cb-bbb5-4ef2-b580-f12bde982264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Function to get POS tag for lemmatization\n",
    "def get_wordnet_pos(word):\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ, \"N\": wordnet.NOUN, \"V\": wordnet.VERB, \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "# Function to perform lemmatization\n",
    "def lemmatize_sentence(sentence):\n",
    "    words = nltk.word_tokenize(sentence)\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word, get_wordnet_pos(word)) for word in words]\n",
    "    return ' '.join(lemmatized_words)\n",
    "\n",
    "# Example usage\n",
    "# sentence = \"The striped bats are hanging on their feet for best\"\n",
    "# lemmatized_sentence = lemmatize_sentence(sentence)\n",
    "# print(lemmatized_sentence)\n",
    "#The strip bat be hang on their foot for best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e960040-ac34-4e53-9532-7fba936b9095",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e594be74-7e2c-48cd-b6d2-ae698c7f1247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "#df['tokenized_comments'] = df['cleaned_comments'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c08dd8-d702-4164-8206-9c5d448d2a30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
